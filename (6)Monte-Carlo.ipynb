{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e0fb4-775d-4105-a6b0-a75a13558f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16b189-82fa-4694-94d5-5888a95a819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that ranks data into quintiles\n",
    "def rank_factors(info):\n",
    "    for item in info.columns.tolist():\n",
    "        string = item + \" Rank\" \n",
    "        info[string] = pd.qcut(info[item], 5, labels = [item + \"1\", item + \"2\", item + \"3\",\n",
    "\n",
    "        item + \"4\", item + \"5\"])\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcb7e2-0bd8-4103-8dfd-4dcf99cde471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates an array of lists of factors for each available asset\n",
    "def fpg_prep(info):\n",
    "    # Drop the columns that do not contain the rankings\n",
    "    state = info.drop(['X', 'Z', 'Y', 'D'], axis=1)\n",
    "    # Drop the returns ranked column and assign remaining info to new \n",
    "    new = state.drop(\"Y Rank\", axis = 1)\n",
    "    # Reset the index of state and drop the names column\n",
    "    state = state.reset_index()\n",
    "    final = []\n",
    "    # For each row, append final with each row as an array of its own\n",
    "    for i in range(0,len(state)):\n",
    "        final.append(state.loc[i, state.columns[1:]].tolist())\n",
    "    # Return both final and new\n",
    "    return final , new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5885629-22a3-473c-b09e-e5b4cbb3aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that mines assocation and lift rules, the 5th quintile returns and the true/false df for the FPG algorithm\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "def rules(final):\n",
    "    # Preprocessing of input argument into true and false for each discretisation\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(final).transform(final)\n",
    "    # Eg is the true/false dataframe in this form for the fp growth algorithm\n",
    "    eg = pd.DataFrame(te_ary , columns=te.columns_)\n",
    "    # True/false column of the highest quintile of returns\n",
    "    high_returns = eg.Y5\n",
    "    # Finding frequent items in data for a minimum support of 5%\n",
    "    freq_items = fpgrowth(eg, min_support=0.05, use_colnames = True)\n",
    "    # Discover association and causal rules\n",
    "    asso_rules = association_rules(freq_items , metric=\"confidence\",min_threshold =0.2)\n",
    "    lift_rules = association_rules(freq_items , metric=\"lift\", min_threshold=1.2)\n",
    "    # Return true\\false dataframe , high returns , and the found\n",
    "    return eg, high_returns , asso_rules , lift_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d3517-0bb2-4a1e-9e96-9632b89eadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get high return rules from rule set\n",
    "def high_ret_rules(asso_rules): \n",
    "    factors = []\n",
    "# For each row, if row contains \"Ret5\", then add that row’s antecedents to the factors array\n",
    "    for index in asso_rules.index.tolist():\n",
    "        #if (list(asso_rules.loc[index, ’consequents’])[0] in [\"Ret5\"]): \n",
    "        if (set([\"Y5\"]).issubset(set(list(asso_rules.loc[index, 'consequents'])))):\n",
    "            factors.append(list(asso_rules.loc[index, 'antecedents']))\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad18237-42e3-4829-8cde-e22f656802bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get rules\n",
    "def get_rules(unique_asso): \n",
    "    associatons = []\n",
    "    for asso in unique_asso:\n",
    "        # Check if each antecedent is in the right format (list) \n",
    "        if (isinstance(asso, list) == False):\n",
    "            associatons.append([asso]) \n",
    "        else:\n",
    "            associatons.append(asso)\n",
    "    # Return list of lists\n",
    "    return associatons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa777b96-dee7-492c-a238-94cb1e6cee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get rules for the period, by using the above functions\n",
    "def rules_for_period(info):\n",
    "    info = rank_factors(info)\n",
    "    final, new = fpg_prep(info)\n",
    "    eg, high_returns , asso_rules , lift_rules = rules(final)\n",
    "    factors = high_ret_rules(asso_rules)\n",
    "    info = info.drop(['X', 'Z', 'Y', 'D'], axis=1)\n",
    "    rules_set = get_rules(factors)\n",
    "    rules_set = list(np.unique(np.array(rules_set)))\n",
    "    if len(rules_set) == 0:\n",
    "          return rules_set , eg, high_returns, info\n",
    "    if (isinstance(rules_set[0], list) == False):\n",
    "        rules_set_2 = []\n",
    "        for i in rules_set:\n",
    "            rules_set_2.append([i])\n",
    "            rules_set = rules_set_2\n",
    "    return rules_set , eg, high_returns, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0490024-a9ec-45ce-9bed-c92060806435",
   "metadata": {},
   "source": [
    "# Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f587d-8280-43ae-83de-885f83bb6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get expected and actual frequency of a rule\n",
    "def expected_freq(info, rule):\n",
    "    # Get number of equites with top quintile Y\n",
    "    num_ret_ind = len(info[info['Y Rank'] == 'Y5'])\n",
    "    \n",
    "    # Calculate expected frequency\n",
    "    mask = info.isin(rule)\n",
    "    filtered = info[mask].dropna(axis = 0, how = 'all')\n",
    "    num_rule_ind = len(filtered)\n",
    "    data_len = len(info)\n",
    "    ef_ind = (num_ret_ind/data_len)*(num_rule_ind/data_len)*data_len\n",
    "    \n",
    "    # Calculate actual frequency\n",
    "    rule.append('Y5')\n",
    "    mask = info.isin(rule)\n",
    "    filtered = info[mask]\n",
    "    filtered = filtered.dropna(thresh=len(rule))\n",
    "    actual_freq = len(filtered)\n",
    "    rule.pop(-1)\n",
    "    return actual_freq, ef_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b55543-059e-4eb6-9da5-0797eccba2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Function to get rules that pass the chi-squared pruning\n",
    "def causal_chi(info, rules):\n",
    "    causal = []\n",
    "    # For each rule, if chi-stat is significant append the rule to the set\n",
    "    for rule in rules:        \n",
    "        if type(rule)==np.str_:\n",
    "            rule = [rule]\n",
    "        actual_freq, ef_ind = expected_freq(info, rule)\n",
    "        stat = ((actual_freq-ef_ind)**2)/ef_ind\n",
    "        dof = len(info['Y Rank'].unique())-1\n",
    "        p = stats.chi2.cdf(stat, dof)\n",
    "        if p > 0.99:\n",
    "            causal.append(rule)\n",
    "    return causal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa2928-c539-46c3-886e-862a3e6dff47",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ceb52-85ab-4a2a-b0d2-535f8dda34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openai wandb\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc4ba3-9dad-414e-8b2e-23ebd1fb22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2661c71-f565-43e0-bee6-74760e1ee3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for Open AI API \n",
    "API_KEY = 'Put API key here'\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e0913-ab45-4b29-8de4-bd0b08a87f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prompt gpt-3.5 turbo\n",
    "def generate_chat_completion(messages, model=\"gpt-3.5-turbo\", temperature=1, max_tokens=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daec38a-8ac4-4830-8d68-91d288688013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part rephrase rule into something the LLM will understand\n",
    "dic = {'1':'very low', '2':'low',\"3\":'medium', '4':'high','5':'very high'}\n",
    "def rephrase(rule):\n",
    "    quant = dic[rule[-1]]\n",
    "    factor = rule[:-1]\n",
    "    return quant, factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989c484-86b8-4eba-baae-16055d8ecccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rules that survived the LLM pruning\n",
    "import time\n",
    "def causal_LLM(rules, content):\n",
    "    causal = []\n",
    "    for rule in rules: \n",
    "        # Creating the prompt for each rule\n",
    "        if type(rule)==np.str_:\n",
    "            rule = [rule]\n",
    "        if len(rule)==1:\n",
    "            quant, factor = rephrase(rule[0])\n",
    "            q = 'Does a ' + quant  + ' ' + factor + ' value cause a very high Y value?'\n",
    "        else:\n",
    "            q = 'Does'\n",
    "            for i in rule[:-1]:\n",
    "                quant, factor = rephrase(i)\n",
    "                q = q + ' a ' + quant + ' ' + factor +' value,'\n",
    "            quant, factor = rephrase(rule[-1])\n",
    "            q = q[:-1] + ' and a ' + quant + ' ' + factor + ' value cause a very high Y value?'\n",
    "        result = None\n",
    "        \n",
    "        # Ask the LLM the prompt\n",
    "        while result is None:\n",
    "            try:\n",
    "                messages = [{\"role\": \"system\", \"content\": content},{\"role\": \"user\", \"content\": q}]\n",
    "                #messages = [{\"role\": \"system\", \"content\": \"you only give one word, yes or no answers, no other answer is acceptable\"},{\"role\": \"user\", \"content\": q}]\n",
    "                response_text = generate_chat_completion(messages)\n",
    "                result = 1\n",
    "            except:\n",
    "                 pass\n",
    "                 print('error')\n",
    "\n",
    "        # Append valid rules to causal set\n",
    "        if response_text[0:3]=='yes' or response_text[0:3]=='Yes':\n",
    "            causal.append(rule)\n",
    "\n",
    "    return causal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a612e-c0cd-4021-85b2-068fe43cc8da",
   "metadata": {},
   "source": [
    "# Odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1fb9e-2f1d-43c1-a210-7ddecf0b3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get fair dataset for a rule\n",
    "def get_fair_datasets(true_control, false_control):\n",
    "    true_match = []\n",
    "    false_match = []\n",
    "    \n",
    "    if true_control.empty or false_control.empty:\n",
    "        return true_match, false_match\n",
    "    \n",
    "    inter = pd.merge(true_control, false_control, how='inner')\n",
    "\n",
    "    # Build the fair datasets\n",
    "    for i, row in inter.iterrows():\n",
    "        mask_false = (false_control == row).all(axis=1)\n",
    "        mask_true = (true_control == row).all(axis=1)\n",
    "        false_match.extend(false_control[mask_false].index.tolist())\n",
    "        true_match.extend(true_control[mask_true].index.tolist())\n",
    "\n",
    "    return true_match, false_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc555f3-7ddc-4788-840e-735981c3306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get odds ratio confidence interval\n",
    "def get_oddsratio_CI(exposure , non_exposure , returns):\n",
    "    # Count for number of times both exposure and non-exposure groups have the consequent\n",
    "    n11 = 0\n",
    "    # Count for number of times the exposure has the consequent and non- exposure groups does not\n",
    "    n12 = 0\n",
    "    # Count for number of times the exposure does not have the consequent and non-exposure groups does\n",
    "    n21 = 0\n",
    "    # Count for number of times both exposure and non-exposure groups do not have the consequent\n",
    "    n22 = 0\n",
    "    for i in range(len(exposure)):\n",
    "    # If both the exposure and non exposure groups have returns in the 5th quantile , increment n11 by one\n",
    "        if (returns.loc[exposure.index[i]] == True) and (returns.loc[ non_exposure.index[i]] == True):\n",
    "            n11 += 1\n",
    "        elif (returns.loc[exposure.index[i]] == True) and (returns.loc[non_exposure.index[i]] == False): \n",
    "            n12 += 1\n",
    "        elif (returns.loc[exposure.index[i]] == False) and (returns.loc[ non_exposure.index[i]] == True):\n",
    "            n21 += 1\n",
    "        elif (returns.loc[exposure.index[i]] == False) and (returns.loc[non_exposure.index[i]] == False): \n",
    "            n22 += 1\n",
    "    # To ensure that you are not dividing by 0, if n12 or n21 are zero, set them to one\n",
    "    if n21 == 0: \n",
    "        n21 = 1\n",
    "    if n12 == 0: \n",
    "        n12 = 1\n",
    "    # Calculate the odds ratio point estimate\n",
    "    odds_ratio = n12/n21\n",
    "    # Compute the lower and upper bounds of the odds ratio’s 80% conficence interval\n",
    "    lower_bound = np.exp(np.log(odds_ratio) - (1.15*np.sqrt((1/n12) + (1/n21 ))))\n",
    "    upper_bound = np.exp(np.log(odds_ratio) + (1.15*np.sqrt((1/n12) + (1/n21 ))))\n",
    "    return lower_bound , upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9f822-ce51-4c96-a52f-964b1beba34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that mines causal rules from established associations\n",
    "def get_causal_rules(eg, rules, returns): \n",
    "    # Array to store mined causal rules \n",
    "    causal_rules = []\n",
    "    for rule in rules:\n",
    "        if type(rule)==np.str_:\n",
    "            rule = [rule]\n",
    "\n",
    "        # Otherwise , for each association antecedent , search rows for when antecedent and true and false\n",
    "        trues = list(np.ones(len(rule), dtype=bool)) \n",
    "        falses = list(np.zeros(len(rule), dtype=bool))\n",
    "        \n",
    "        true_indices = np.all(eg[rule].values == trues, axis=1)\n",
    "        false_indices = np.all(eg[rule].values == falses, axis=1)\n",
    "        true = eg[true_indices]\n",
    "        false = eg[false_indices]\n",
    "\n",
    "        # Remove the returns columns and columns with antecedants in question. Only the control variables remain\n",
    "        remove = [\"Y1\", \"Y2\", \"Y3\", \"Y4\", 'Y5'] \n",
    "        for cond in rule:\n",
    "            remove.append(cond[:-1] + \"1\") \n",
    "            remove.append(cond[:-1] + \"2\") \n",
    "            remove.append(cond[:-1] + \"3\")\n",
    "            remove.append(cond[:-1] + \"4\")\n",
    "            remove.append(cond[:-1] + \"5\")\n",
    "\n",
    "        \n",
    "        true_control = true.drop(remove , axis = 1)\n",
    "        false_control = false.drop(remove , axis = 1)\n",
    "        # Drop duplicates from true and false control sets to ensure that there is at most one set of matching rows\n",
    "\n",
    "        \n",
    "        true_control = true_control.drop_duplicates(subset = true_control.columns , keep='first')\n",
    "        false_control = false_control.drop_duplicates(subset = false_control.columns , keep='first')\n",
    "        \n",
    "        # Retrieve the date indices from the fair datasets\n",
    "        true_match , false_match = get_fair_datasets(true_control, false_control)\n",
    "        \n",
    "        # Getting returns columns for the rows of the fair dataset\n",
    "        exposure_returns = returns[true_match]\n",
    "        non_exposure_returns = returns[false_match]\n",
    "\n",
    "        # Compute the bounds of the rule’s odd ratio confidence interval\n",
    "        lower, _ = get_oddsratio_CI(exposure_returns, non_exposure_returns , returns)\n",
    "\n",
    "        #print(lower)\n",
    "        if (lower > 1): \n",
    "            causal_rules.append(rule)\n",
    "    return causal_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc632f-ac64-477e-9f81-fca85f8e14f3",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced5407-7eaa-45b0-93c3-64bdbbdd09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets all association rules and applies causal pruning to them for a given dataset\n",
    "def get_all_rule_sets(period_data, content):\n",
    "    assoc_rules, eg, ret, info = rules_for_period(period_data)\n",
    "\n",
    "    chi = causal_chi(info, assoc_rules)\n",
    "\n",
    "    LMM = causal_LLM(assoc_rules, content)\n",
    "\n",
    "    odds = get_causal_rules(eg, assoc_rules, ret)\n",
    "    \n",
    "    print('done')\n",
    "    return chi, LMM, odds, assoc_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d16e3-0bc2-46d2-84fa-606404cb18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets unique elements from list\n",
    "def get_unique_elements(input_list):\n",
    "    unique_elements = []\n",
    "    for element in input_list:\n",
    "        if element not in unique_elements:\n",
    "            unique_elements.append(element)\n",
    "    return unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f071e8-0846-4bac-b2bf-66a4b5a09a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Makes the ensemble models from the causal rule set\n",
    "def combine_rules(rule_set1, rule_set2):\n",
    "    or_rules = get_unique_elements(rule_set1+rule_set2)\n",
    "    #or_rules =list(np.unique(np.array(rule_set1+rule_set2)))\n",
    "    and_rules = [value for value in rule_set1 if value in rule_set2]\n",
    "    return or_rules, and_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb9b14-e928-4339-ab15-1c1ebe9b2187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gets associations rules from data for association rule , causal pruning and ensemble methods\n",
    "def simulation(data, content):\n",
    "    \n",
    "    # Get ARM and CRM rulesets\n",
    "    chi, LLM, odds, assoc_rules = get_all_rule_sets(data, content)\n",
    "    \n",
    "    # Get ensemble models\n",
    "    chi_or_LLM, chi_and_LLM = combine_rules(chi, LLM)\n",
    "    chi_or_odds, chi_and_odds = combine_rules(chi, odds)\n",
    "    LLM_or_odds, LLM_and_odds = combine_rules(LLM, odds)\n",
    "    chi_or_odds_or_LLM, _ = combine_rules(LLM_or_odds, chi)\n",
    "    _, chi_and_odds_and_LLM = combine_rules(LLM_and_odds, chi)\n",
    "        \n",
    "        \n",
    "    return assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3b9e6-501a-4f57-996c-28071204334b",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf878d-873e-4a11-bf83-8330b28c6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with causal structure 1\n",
    "def df_1():\n",
    "    # Generate random normal numbers\n",
    "    data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    # Create DataFrame from random normal numbers\n",
    "    df1 = pd.DataFrame(data, columns=['X'])\n",
    "\n",
    "    df1['Z'] = np.random.normal(0, 1, 1000) \n",
    "    df1['D'] = np.random.normal(0, 1, 1000) \n",
    "    df1['Y'] = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e7a94-b2c9-4ce5-a5d6-581ee6147bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with causal structure 2\n",
    "def df_2():\n",
    "    # Generate random normal numbers\n",
    "    data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    # Create DataFrame from random normal numbers\n",
    "    df2 = pd.DataFrame(data, columns=['X'])\n",
    "\n",
    "    df2['Z'] = np.random.normal(0, 1, 1000) \n",
    "    df2['D'] = np.random.normal(0, 1, 1000)\n",
    "    df2['Y'] = np.random.normal(df2['X']+df2['Z'], 1, 1000)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9c5b4-e980-4dde-af85-daf47ade12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with causal structure 3\n",
    "def df_3():\n",
    "    # Fork\n",
    "    data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    # Create DataFrame from random normal numbers\n",
    "    df3 = pd.DataFrame(data, columns=['X'])\n",
    "\n",
    "    df3['Z'] = np.random.normal(df3['X'], 1, 1000) \n",
    "    df3['D'] = np.random.normal(0, 1, 1000)\n",
    "    df3['Y'] = np.random.normal(df3['X'], 1, 1000) \n",
    "\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81959733-6929-4242-b515-0cc5725c8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with causal structure 4\n",
    "def df_4():\n",
    "    # IMMORALITY\n",
    "    data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    # Create DataFrame from random normal numbers\n",
    "    df4 = pd.DataFrame(data, columns=['X'])\n",
    "\n",
    "    df4['Y'] = np.random.normal(0, 1, 1000) \n",
    "    df4['D'] = np.random.normal(0, 1, 1000)\n",
    "    df4['Z'] = np.random.normal((df4['X']+df4['Y']), 1, 1000) \n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fc07e-0191-4cb9-8378-f8cdc85b1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with causal structure 5\n",
    "def df_5():\n",
    "    # CHAIN\n",
    "    data = np.random.normal(0, 1, 1000) \n",
    "\n",
    "    # Create DataFrame from random normal numbers\n",
    "    df5 = pd.DataFrame(data, columns=['X'])\n",
    "\n",
    "    df5['Z'] = np.random.normal((df5['X']), 1, 1000) \n",
    "    df5['D'] = np.random.normal(0, 1, 1000)\n",
    "    df5['Y'] = np.random.normal((df5['Z']), 1, 1000) \n",
    "\n",
    "    return df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca806a4-27b3-4ec0-9044-8531c6857551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the simulation 1000 times for causal data structure 1\n",
    "\n",
    "column_names = ['assoc_rules','chi', 'LLM', 'odds', 'chi_or_LLM', 'chi_and_LLM','chi_or_odds', 'chi_and_odds', 'LLM_or_odds', 'LLM_and_odds', 'chi_or_odds_or_LLM', 'chi_and_odds_and_LLM']\n",
    "# Create an empty DataFrame with column names\n",
    "results1 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df1 = df_1()\n",
    "    content =  \"you only give one word, yes or no answers, no other answer is acceptable. X, Z, D and Y are independently randomly generated numbers\"\n",
    "    assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM = simulation(df1, content)\n",
    "    results1.loc[len(results1)] = [assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM,chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ae6da-babe-4745-9652-56ff3487e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbd29d-d41f-44db-8b42-9ba51e82aba7",
   "metadata": {},
   "source": [
    "print(assoc_rules)\n",
    "print(chi)\n",
    "print(LLM)\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd2cdd-eb15-43b6-98d0-3443ad9707ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the simulation 1000 times for causal data structure 2\n",
    "\n",
    "column_names = ['assoc_rules','chi', 'LLM', 'odds', 'chi_or_LLM', 'chi_and_LLM','chi_or_odds', 'chi_and_odds', 'LLM_or_odds', 'LLM_and_odds', 'chi_or_odds_or_LLM', 'chi_and_odds_and_LLM']\n",
    "# Create an empty DataFrame with column names\n",
    "results2 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    \n",
    "    df2 = df_2()\n",
    "    content =  \"you only give one word, yes or no answers, no other answer is acceptable. X, D and Z are independently randomly generated numbers, Y = X + Z\"\n",
    "    assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM = simulation(df2, content)\n",
    "    results2.loc[len(results2)] = [assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM,chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM]\n",
    "    \n",
    "    #end_time = time.time()\n",
    "    #elapsed_time = end_time - start_time\n",
    "    #print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42f692-6a03-4a73-ae8d-e8ab31f9ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc2b37-f411-4c80-858c-358bad2afc9c",
   "metadata": {},
   "source": [
    "print(assoc_rules)\n",
    "print(chi)\n",
    "print(LLM)\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd316da-17c7-42b1-88d1-7437a2d987f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the simulation 1000 times for causal data structure 3\n",
    "\n",
    "column_names = ['assoc_rules','chi', 'LLM', 'odds', 'chi_or_LLM', 'chi_and_LLM','chi_or_odds', 'chi_and_odds', 'LLM_or_odds', 'LLM_and_odds', 'chi_or_odds_or_LLM', 'chi_and_odds_and_LLM']\n",
    "# Create an empty DataFrame with column names\n",
    "results3 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df3 = df_3()\n",
    "    content =  \"you only give one word, yes or no answers, no other answer is acceptable. X and D are randomly generated numbers, Z and Y are independent randomly generated numbers with mean X\"\n",
    "    assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM = simulation(df3, content)\n",
    "    results3.loc[len(results3)] = [assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM,chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561c418-9f53-444b-9e2e-ee101a6691c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b23eb0-84bf-4e49-9370-0960c41482af",
   "metadata": {},
   "source": [
    "print(assoc_rules)\n",
    "print(chi)\n",
    "print(LLM)\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df39b9-300a-4a52-844f-9b0e7847ae77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the simulation 1000 times for causal data structure 4\n",
    "\n",
    "column_names = ['assoc_rules','chi', 'LLM', 'odds', 'chi_or_LLM', 'chi_and_LLM','chi_or_odds', 'chi_and_odds', 'LLM_or_odds', 'LLM_and_odds', 'chi_or_odds_or_LLM', 'chi_and_odds_and_LLM']\n",
    "# Create an empty DataFrame with column names\n",
    "results4 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "        \n",
    "    df4 = df_4()\n",
    "    content =  \"you only give one word, yes or no answers, no other answer is acceptable. X, D and Y are independent randomly generated numbers, Z is a randomly generated numbers with mean X + Y\"\n",
    "    assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM = simulation(df4, content)\n",
    "    results4.loc[len(results4)] = [assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM,chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b31253-de60-42f6-a77c-2ff6076d88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26804da8-8cdb-49f7-b25a-4f5b43693179",
   "metadata": {},
   "source": [
    "print(assoc_rules)\n",
    "print(chi)\n",
    "print(LLM)\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd812e7-5551-4591-a08f-0f95251dae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the simulation 1000 times for causal data structure 5\n",
    "\n",
    "column_names = ['assoc_rules','chi', 'LLM', 'odds', 'chi_or_LLM', 'chi_and_LLM','chi_or_odds', 'chi_and_odds', 'LLM_or_odds', 'LLM_and_odds', 'chi_or_odds_or_LLM', 'chi_and_odds_and_LLM']\n",
    "# Create an empty DataFrame with column names\n",
    "results5 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in range(1000):\n",
    "    start_time = time.time()\n",
    "        \n",
    "    df5 = df_5()\n",
    "    content =  \"you only give one word, yes or no answers, no other answer is acceptable. X and D are randomly generated numbers, Z is randomly generated numbers with mean X, Y is randomly generated numbers with mean Z\"\n",
    "    assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM, chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM = simulation(df5, content)\n",
    "    results5.loc[len(results5)] = [assoc_rules, chi, LLM, odds, chi_or_LLM, chi_and_LLM,chi_or_odds, chi_and_odds, LLM_or_odds, LLM_and_odds, chi_or_odds_or_LLM, chi_and_odds_and_LLM]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8c498-e392-4d46-8c60-728936bbb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "results5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7ab95-732c-4feb-ba1b-94fbce715c6b",
   "metadata": {},
   "source": [
    "print(assoc_rules)\n",
    "print(chi)\n",
    "print(LLM)\n",
    "print(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506d682-8951-44b8-9144-0da5c60e8af2",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e3a14-8d7e-4cd5-bc5b-210ecb6971b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for calculating performance metrics for the MC experiments\n",
    "\n",
    "# Counts empty rulesets\n",
    "def count_empty(data):\n",
    "    empty_counts = {}\n",
    "\n",
    "    # Iterate over each column\n",
    "    for column in data.columns:\n",
    "        # Count the number of empty lists in the column\n",
    "        empty_counts[column] = data[column].apply(lambda x: len(x) == 0).sum()\n",
    "    \n",
    "    return empty_counts\n",
    "\n",
    "# Finds mean length of rulesets\n",
    "def mean_len(data):\n",
    "    mean_lengths = {}\n",
    "\n",
    "    # Iterate over each column\n",
    "    for column in data.columns:\n",
    "        # Compute the mean length of the lists in the column\n",
    "        mean_lengths[column] = np.mean(data[column].apply(len))\n",
    "    return mean_lengths\n",
    "\n",
    "# Counts number of causal rules in set\n",
    "def Caus_rule_count(data, causal_lis):\n",
    "    list_counts = {}\n",
    "\n",
    "    # Iterate over each column\n",
    "    for column in data.columns:\n",
    "        # Count the number of inner lists from each list in the column that are present in the external list\n",
    "        big_list = data[column].explode().tolist()\n",
    "        caus_sum = 0\n",
    "        for r in causal_lis:\n",
    "            caus_sum += big_list.count(r)\n",
    "\n",
    "        list_counts[column] = {'causal':caus_sum, 'total':len(big_list)}\n",
    "    return list_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a084734-2519-41a4-987f-885786fb8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a results table for causal structure 1\n",
    "results_table_1 = pd.DataFrame(count_empty(results1), ['Number of Empty Sets',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4876778-b0ea-4651-9a9e-61274e7f277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mean rule length to data\n",
    "results_table_1.loc['Mean Rule Length'] = mean_len(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4c820-2fa7-450b-b3e9-0340e5073188",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da29b7c-df9f-453c-9c8c-ca70bcb4cb10",
   "metadata": {},
   "source": [
    "## results 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b065c8-47ae-41c1-9fbf-0bb361378476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists of legit causal rules\n",
    "causal_lis = [['X5'],['Z5'], ['X5','Z5'], ['Z5','X5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a5a19-45fc-498c-b26c-4b4bc7232979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a results table for causal structure 2\n",
    "results_table_2 = pd.DataFrame(count_empty(results2), ['Number of Empty Sets',])\n",
    "# Add mean rule length to data\n",
    "results_table_2.loc['Mean Rule Length'] = mean_len(results2)\n",
    "\n",
    "# Add Percentage of rules mined that are causal  and Percentage of causal rules mind that could have been to results\n",
    "results_table_2.loc['Percentage of rules mined that are causal '] = Caus_rule_count(results2, causal_lis)\n",
    "results_table_2.loc['Percentage of causal rules mind that could have been'] = Caus_rule_count(results2, causal_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb608d08-675f-423d-91bf-8ed0a1d40322",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346df4b-4dd5-44c6-8734-b4bfdaf1242a",
   "metadata": {},
   "source": [
    "## Resuts 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2ee72-c9a0-4bcb-93d4-2858f42014e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists of legit causal rules\n",
    "causal_lis = [['X5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829132ae-0951-4737-b054-701dd9afc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a results table for causal structure 2\n",
    "results_table_3 = pd.DataFrame(count_empty(results3), ['Number of Empty Sets',])\n",
    "# Add mean rule length to data\n",
    "results_table_3.loc['Mean Rule Length'] = mean_len(results3)\n",
    "\n",
    "# Add Percentage of rules mined that are causal  and Percentage of causal rules mind that could have been to results\n",
    "results_table_3.loc['Percentage of rules mined that are causal '] = Caus_rule_count(results3, causal_lis)\n",
    "results_table_3.loc['Percentage of causal rules mind that could have been'] = Caus_rule_count(results3, causal_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5b293-97b0-40cc-b2c2-ba274b8bf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354b802-71ea-4777-a177-3aad7df7c6b1",
   "metadata": {},
   "source": [
    "## Results 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105f2a7-dfd5-4b7c-806e-b0ee5ef179e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a results table for causal structure 4\n",
    "results_table_4 = pd.DataFrame(count_empty(results4), ['Number of Empty Sets',])\n",
    "results_table_4.loc['Mean Rule Length'] = mean_len(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a6e6a-6ca4-433c-b0a3-56ada5943a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262f122-7a5e-4258-ae56-1d96e47ccfb1",
   "metadata": {},
   "source": [
    "# Results 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cbceb-20f2-47c5-b979-526a4d2e0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists of legit causal rules\n",
    "causal_lis = [['X5'],['Z5'], ['X5','Z5'], ['Z5','X5']] # CHECK THAT Z SHOULD BE IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f85453-b75a-45a6-905d-2d7dbf1d431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a results table for causal structure 5\n",
    "results_table_5 = pd.DataFrame(count_empty(results5), ['Number of Empty Sets',])\n",
    "# Add mean rule length to data\n",
    "results_table_5.loc['Mean Rule Length'] = mean_len(results5)\n",
    "\n",
    "# Add Percentage of rules mined that are causal  and Percentage of causal rules mind that could have been to results\n",
    "results_table_5.loc['Percentage of rules mined that are causal '] = Caus_rule_count(results5, causal_lis)\n",
    "results_table_5.loc['Percentage of causal rules mind that could have been'] = Caus_rule_count(results5, causal_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b39f52-1746-4005-ae86-9b00b7ca76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b6190-1269-4b70-945f-db3b89d8de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop results tables \n",
    "results_table_1.to_csv('results_table_1.csv',index=True)\n",
    "results_table_2.to_csv('results_table_2.csv',index=True)\n",
    "results_table_3.to_csv('results_table_3.csv',index=True)\n",
    "results_table_4.to_csv('results_table_4.csv',index=True)\n",
    "results_table_5.to_csv('results_table_5.csv',index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
